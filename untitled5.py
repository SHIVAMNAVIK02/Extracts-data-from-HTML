# -*- coding: utf-8 -*-
"""Untitled5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GLsGTYGbGGjb9KHEZ5s-hlm2iBxkZX0U
"""

import os
import pandas as pd
from bs4 import BeautifulSoup

def extract_table_data(html_file):
    with open(html_file, 'r', encoding='utf-8') as f:
        soup = BeautifulSoup(f, 'html.parser')

    all_data = []

    for table in soup.find_all('table'):
        table_title = ''
        if table.caption:
            table_title = table.caption.text.strip()

        header_row = None
        rows = table.find_all('tr')
        if rows:
            header_row = [th.text.strip() for th in rows[0].find_all('th')]
            if not header_row:
                header_row = [td.text.strip() for td in rows[0].find_all('td')]

            data_rows = rows[1:] if header_row else rows

            for row in data_rows:
                cells = row.find_all('td')
                label = cells[0].text.strip() if cells else ""
                values = cells[1:] if cells else []

                for i, value_cell in enumerate(values):
                    value = "".join(value.strip() for value in value_cell.stripped_strings)

                    if header_row and i < len(header_row):
                        column_header = header_row[i]
                    else:
                        column_header = str(i+1)

                    all_data.append({
                        'file_name': html_file,
                        'label': label,
                        'table_title': table_title,
                        'column_header': column_header,
                        'value': value
                    })
    return all_data


def process_all_files(directory):
    all_extracted_data = []
    for filename in os.listdir(directory):
        if filename.endswith(".html"):
            file_path = os.path.join(directory, filename)
            extracted_data = extract_table_data(file_path)
            all_extracted_data.extend(extracted_data)
    return all_extracted_data


if __name__ == "__main__":
    html_directory = "."  # Current directory - put HTML files here or change the path

    # Example of setting a specific directory:
    # Shivam_Navik

    all_data = process_all_files(html_directory)

    df = pd.DataFrame(all_data)
    output_csv = "output.csv"
    df.to_csv(output_csv, index=False, encoding='utf-8')

    print(f"Data extracted and saved to {output_csv}")

data = pd.read_csv("/content/output.csv")

data

